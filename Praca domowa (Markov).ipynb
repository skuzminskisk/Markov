{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74bca0ad-3e1d-4a5a-94cf-a19a397908d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sebastian Kuźmiński - sk149029\n",
    "# załadowanie PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count\n",
    "import random\n",
    "# spark = SparkSession.builder.appName(\"Markov\").getOrCreate() - wykorzystywane w Google Colab\n",
    "\n",
    "# funkcja tworząca model przejść Markowa, tworzy pary z aktualnego słowa i następnego, następnie zamienia je na DataFrame (dwie kolumny: current, next)\n",
    "def markov_model(words): \n",
    "    pairs = [(words[i], words[i+1]) \n",
    "             for i in range(len(words)-1)]\n",
    "    df = spark.createDataFrame(pairs, [\"current\", \"next\"])\n",
    "    # obliczenie ile razy powtarzają się pary słów (current + next)\n",
    "    probability_df = (\n",
    "        df.groupBy(\"current\", \"next\")\n",
    "        .agg(count(\"*\").alias(\"count\"))\n",
    "    )\n",
    "    # obliczenie ile razy powtarza się słowo w kolumnie current\n",
    "    total_df = (\n",
    "        probability_df.groupBy(\"current\")\n",
    "        .agg(count(\"*\").alias(\"total\"))\n",
    "    )\n",
    "    # wyliczenie prawdopodobieństwa (count / total)    \n",
    "    markov_df = (\n",
    "        probability_df.join(total_df, \"current\")\n",
    "        .withColumn(\"probability\", col(\"count\") / col(\"total\"))\n",
    "    )\n",
    "    return markov_df\n",
    "\n",
    "# funkcja losuje kolejne słowo na podstawie prawdopodobieństw (zamiana DataFrame utworzonego przez Spark na zwykłą pythonową listę wierszy w celu użycia przez random)\n",
    "def next_state(current):\n",
    "    rows = markov_df.filter(col(\"current\") == current).collect()\n",
    "    if not rows:\n",
    "        return None\n",
    "    nexts = [r[\"next\"] for r in rows]\n",
    "    probs = [r[\"probability\"] for r in rows]\n",
    "    return random.choices(nexts, weights=probs)[0]\n",
    "\n",
    "# funkcja generuje kolejne słowa, do momentu aż osiągnie ustaloną długość lub kolejne słowo nie będzie istnieć\n",
    "def generate_text(length, start):\n",
    "    text = start\n",
    "    current = start\n",
    "    for _ in range(length - 1):\n",
    "        nxt = next_state(current)\n",
    "        if not nxt:\n",
    "            break\n",
    "        text += \" \" + nxt\n",
    "        current = nxt\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "018d4919-6723-463f-9493-e0c231fb3f03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Słowo start: kiedy\n\nkiedy wymawiam słowo cisza, niszczę ją\nkiedy wymawiam słowo przyszłość, pierwsza sylaba odchodzi już do przeszłości. kiedy wymawiam słowo cisza, niszczę ją\nkiedy wymawiam słowo cisza, niszczę ją\nkiedy wymawiam słowo przyszłość, pierwsza sylaba odchodzi już do przeszłości. kiedy wymawiam słowo cisza, niszczę ją\nkiedy wymawiam słowo cisza, niszczę ją\n"
     ]
    }
   ],
   "source": [
    "# WARIANT 1: krótki jednowierszowy tekst\n",
    "text = \"kiedy wymawiam słowo przyszłość, pierwsza sylaba odchodzi już do przeszłości. kiedy wymawiam słowo cisza, niszczę ją\"\n",
    "slowo_start = \"kiedy\"\n",
    "print(f\"Słowo start: {slowo_start}\\n\")\n",
    "\n",
    "words = text.lower().split()\n",
    "markov_df = markov_model(words)\n",
    "\n",
    "for _ in range(5):\n",
    "    print(generate_text(20, slowo_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d57196a7-0817-4adb-8bad-02f6d738da3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Słowo start: nic\n\nnic dwa razy się nie zdarzy z tej przyczyny zrodziliśmy się nie zdarza i nie zdarza i pomrzemy bez wprawy\nnic dwa razy się bez wprawy i nie zdarzy z tej przyczyny zrodziliśmy się nie zdarza i nie zdarzy z\nnic dwa razy się bez rutyny choćbyśmy uczniami byli najtępszymi w szkole świata\nnic dwa razy się nie zdarza i pomrzemy bez wprawy i pomrzemy bez wprawy i pomrzemy bez wprawy i nie\nnic dwa razy się bez rutyny choćbyśmy uczniami byli najtępszymi w szkole świata\n"
     ]
    }
   ],
   "source": [
    "# WARIANT 2: wielowierszowy tekst Wisławy Szymborskiej\n",
    "wiersz = \"\"\"\n",
    "nic dwa razy się nie zdarza i nie zdarzy\n",
    "z tej przyczyny zrodziliśmy się bez wprawy\n",
    "i pomrzemy bez rutyny\n",
    "choćbyśmy uczniami byli najtępszymi w szkole świata\n",
    "\"\"\"\n",
    "text = wiersz\n",
    "slowo_start = \"nic\"\n",
    "print(f\"Słowo start: {slowo_start}\\n\")\n",
    "\n",
    "words = text.lower().split()\n",
    "markov_df = markov_model(words)\n",
    "\n",
    "for _ in range(5):\n",
    "    print(generate_text(20, slowo_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e323e0c2-2bef-48c2-be17-c08b73c79a4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Słowo startowe: nokia\n\nnokia & take a date now all will be revealed. po box 114/14 tcr/w1 filthy films &xxx pics straight to\nnokia tone of music to claim this is currently 500 pounds - double mins and u have important messages &\nnokia 3510i colour flag & doublemins & nokia logo&pic message is brought to activate, just call germany for 1st week!\nnokia to 86688 only five pounds of a top ringtone order, ref number 0844 861 85 85. no ads 150p.\nnokia to receive search postcode this is currently 500 pounds - tells u have won a callback orno to text\n"
     ]
    }
   ],
   "source": [
    "# WARIANT 3: plik spam.csv (pobrany z https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)\n",
    "# dodatkowe biblioteki w celu pobrania pliku z linku\n",
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# pobranie pliku\n",
    "url = \"https://raw.githubusercontent.com/skuzminskisk/Markov/main/spam.csv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# wczytanie pliku do bufora pamięci, następnie z bufora do DataFrame Spark przez Pandas\n",
    "data_buffer = io.StringIO(response.text)\n",
    "pdf = pd.read_csv(data_buffer, encoding=\"utf-8\")\n",
    "df = spark.createDataFrame(pdf)\n",
    "\n",
    "# w pliku znajdują się dwie kolumny (v1, v2). w v1 znajdują się wiersze ze słowem \"ham\" oraz \"spam\". filtruje tylko \"spam\"\n",
    "spam_df = df.filter(col(\"v1\") == \"spam\")\n",
    "# następnie pobieram przefiltrowane wiadomości z kolumny \"v2\"\n",
    "messages = [row[\"v2\"] for row in spam_df.collect() if row[\"v2\"]]\n",
    "# połączenie wiadomości w jeden tekst\n",
    "text = \" \".join(messages).lower()\n",
    "\n",
    "words = text.lower().split()\n",
    "markov_df = markov_model(words)\n",
    "\n",
    "# nie wiem jakiego konkretnie słowa użyć jako start, losuje z dostępnych\n",
    "# slowo_start = \"tekst\"\n",
    "slowo_start = random.choice(words)\n",
    "print(f\"Słowo startowe: {slowo_start}\\n\")\n",
    "\n",
    "for _ in range(5):\n",
    "    print(generate_text(20, slowo_start))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Praca domowa (Markov)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}